{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>consumer_key</th>\n",
       "      <th>consumer_secret</th>\n",
       "      <th>access_token</th>\n",
       "      <th>bearer_token</th>\n",
       "      <th>access_token_secret</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qTi2G4s8zuybhF5LReyIGvQpx</td>\n",
       "      <td>a0nj2L7DRz3LktHhei4nG7y4ymNnDD7LiIqQmLnw3thzN4...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AAAAAAAAAAAAAAAAAAAAAJkHNQEAAAAAqsEpKXKU8XlNgr...</td>\n",
       "      <td>740937600475795456-rDP7E53ht8AalwPMgNMYohUv4VF...</td>\n",
       "      <td>yETFBKuwYcKxt6a246GeBOBsNCYBVc46aV5wqzEt3Tx7D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                consumer_key  \\\n",
       "0  qTi2G4s8zuybhF5LReyIGvQpx   \n",
       "\n",
       "                                     consumer_secret  access_token  \\\n",
       "0  a0nj2L7DRz3LktHhei4nG7y4ymNnDD7LiIqQmLnw3thzN4...           NaN   \n",
       "\n",
       "                                        bearer_token  \\\n",
       "0  AAAAAAAAAAAAAAAAAAAAAJkHNQEAAAAAqsEpKXKU8XlNgr...   \n",
       "\n",
       "                                 access_token_secret  \\\n",
       "0  740937600475795456-rDP7E53ht8AalwPMgNMYohUv4VF...   \n",
       "\n",
       "                                      Unnamed: 5  \n",
       "0  yETFBKuwYcKxt6a246GeBOBsNCYBVc46aV5wqzEt3Tx7D  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('twitter_api.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = df['consumer_key'][0]\n",
    "consumer_secret = \n",
    "access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qTi2G4s8zuybhF5LReyIGvQpx'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consumer_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler('qTi2G4s8zuybhF5LReyIGvQpx', 'a0nj2L7DRz3LktHhei4nG7y4ymNnDD7LiIqQmLnw3thzN4ufQb')\n",
    "auth.set_access_token(\"740937600475795456-rDP7E53ht8AalwPMgNMYohUv4VFuBBW\", \"yETFBKuwYcKxt6a246GeBOBsNCYBVc46aV5wqzEt3Tx7D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create API object\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication OK\n"
     ]
    }
   ],
   "source": [
    "# Verify credentials:\n",
    "try:\n",
    "    api.verify_credentials()\n",
    "    print(\"Authentication OK\")\n",
    "except:\n",
    "    print(\"Error during authentication\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably I am going to use the category:\n",
    "* methods for Trends (geographical locations)\n",
    "* methods for User Timelines\n",
    "* Methods for Users\n",
    "* Methods for Search (in all accounts)\n",
    "* Methods for Streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claypole\n",
      "#AEWDynamite\n",
      "Shaq\n",
      "#MarriedAtFirstSight\n",
      "#TheChallenge36\n",
      "jisoo\n",
      "Lisca\n",
      "#SN10\n",
      "Sevilla\n",
      "#Sanrem2021\n",
      "Pottker\n",
      "TJ McConnell\n",
      "Barcelona\n",
      "lucas lima\n",
      "Capaldo\n",
      "Lucas Santos\n",
      "VAI NEVAR AMANH√É\n",
      "Piqu√©\n",
      "Pinares\n",
      "Ferreira\n",
      "Russo\n",
      "Ocampos\n",
      "Cardona\n",
      "Lenglet\n",
      "Elodie\n",
      "Jade Cargill\n",
      "Mancini\n",
      "JJ Dillon\n",
      "Big T\n",
      "Lopetegui\n",
      "Neanderthal\n",
      "Carine\n",
      "Mingueza\n",
      "Tully\n",
      "Rashford\n",
      "Airton\n",
      "„É©„ÉÉ„Éó„Éê„Éà„É´\n",
      "ter stegen\n",
      "Vanderson\n",
      "Otero\n",
      "ÁîüÁêÜÁî®ÂìÅ\n",
      "Âπ≥ÂùáË≥ÉÈáë\n",
      "ÈüìÂõΩ‰ª•‰∏ã\n",
      "Alien X\n",
      "Braga\n",
      "Gabriel Silva\n",
      "Rojas\n",
      "Valdiri\n",
      "Suso\n",
      "TRAFICANTE DE ATLANTA\n"
     ]
    }
   ],
   "source": [
    "# Method for trends.\n",
    "trends_result = api.trends_place(1)\n",
    "for trend in trends_result[0]['trends']:\n",
    "    print(trend['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'timeline = api.home_timeline()\\nfor tweet in timeline:\\n    print(f\"{tweet.user.name} said {tweet.text}\")'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# method for user timelines\n",
    "# My timeline 20 elements.\n",
    "'''timeline = api.home_timeline()\n",
    "for tweet in timeline:\n",
    "    print(f\"{tweet.user.name} said {tweet.text}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User details:\n",
      "Elon Musk\n",
      "\n",
      "\n",
      "Last 20 Followers:\n",
      "elia\n",
      "Friendly Autarchist\n",
      "Kevin Paquette\n",
      "ü™ê\n",
      "SAURABH SARAP\n",
      "Christopheduval\n",
      "Collin Stevenson\n",
      "zhanghd\n",
      "Michael Chisaba\n",
      "stephen carter\n",
      "Ish_\n",
      "jack Santos\n",
      "Maiky\n",
      "London NYY NYK NYG\n",
      "Juanchi\n",
      "Elliot McLeod Zenonos\n",
      "46\n",
      "Nitish Kumar\n",
      "richard braxton\n",
      "Francise Angeline\n"
     ]
    }
   ],
   "source": [
    "# Methods for Users:\n",
    "\n",
    "user = api.get_user(\"elonmusk\")\n",
    "\n",
    "print(\"User details:\")\n",
    "print(user.name)\n",
    "print(user.description)\n",
    "print(user.location)\n",
    "\n",
    "print(\"Last 20 Followers:\")\n",
    "for follower in user.followers():\n",
    "    print(follower.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calefyb:RT @essay_writer47: Hire our legit services in;\n",
      "\n",
      "#Paper pay\n",
      "#Math\n",
      "#Chem\n",
      "#Do my homework\n",
      "#Online class\n",
      "#Religion\n",
      "#history \n",
      "#Econometrics\n",
      "#En‚Ä¶\n",
      "sivaramaiah:@bridgecrewio Python Programming language complete information like free software to download, tutorials for learni‚Ä¶ https://t.co/JOKhfCz98i\n",
      "prof cecil philiph:Hire our legit services in;\n",
      "#Essay due\n",
      "#Paper write\n",
      "#English\n",
      "#Paper pay\n",
      "#Someone help paper\n",
      "#Do my homework\n",
      "#Online‚Ä¶ https://t.co/W5bQnGCV61\n",
      "Ayush Sharma:RT @JovianML: More importantly, you‚Äôll build the following projects:\n",
      "\n",
      "1. Web Scraping with Python\n",
      "2. Exploratory Data Analysis with Python‚Ä¶\n",
      "Front End Tweets:RT @naukarshah: So here is the refined &amp; updated version of Indian News in Chinese Media project.\n",
      "\n",
      "https://t.co/9H1i8RlWhp.\n",
      "\n",
      "Better on PC/L‚Ä¶\n",
      "#30DaysOfCode:RT @tutslink: https://t.co/KUf9z0tzFU\n",
      "Looking for resources as #FREE #Ebooks, #TECH #VIDEOS,#ARTICLES,#MCQ,#FULLFORMS . Well visit Tutorial‚Ä¶\n",
      "BashNano:RT @gp_pulipaka: Introduction to #ReinforcementLearning. #BigData #Analytics #DataScience #AI #MachineLearning #IoT #IIoT #PyTorch #Python‚Ä¶\n",
      "Machine Learning Bot:RT @JovianML: The seven courses are:\n",
      "\n",
      "1. Programming with Python\n",
      "2. Statistics for Data Science\n",
      "3. Data Analysis with Python\n",
      "4. Data Visual‚Ä¶\n",
      "Tutorials Link:https://t.co/KUf9z0tzFU\n",
      "Looking for resources as #FREE #Ebooks, #TECH #VIDEOS,#ARTICLES,#MCQ,#FULLFORMS . Well visi‚Ä¶ https://t.co/NmeW7hzhlQ\n",
      "Ayush Sharma:RT @JovianML: The seven courses are:\n",
      "\n",
      "1. Programming with Python\n",
      "2. Statistics for Data Science\n",
      "3. Data Analysis with Python\n",
      "4. Data Visual‚Ä¶\n",
      "dr J.T. Burman üéì:@tomrichardson80 @arichardson_phi Budget constraints are what led Monty Python to use coconut shells, in Holy Grail‚Ä¶ https://t.co/ICQlWNste7\n",
      "Casey Hillüëª:@florinpop1705 Python is a safe bet, if you want to be relevant in the AI &amp; ML space. Interestingly enough, NLP has‚Ä¶ https://t.co/oCJMZ9jpt4\n",
      "d jual ferrarossa!:Python ‚úÖ\n",
      "Next: SQL\n",
      "And note that i self learn all of these skills...udemy, coursera, geek4geeks are all my besties‚Ä¶ https://t.co/sdNCB7gzXY\n"
     ]
    }
   ],
   "source": [
    "# Methods for Search \n",
    "\n",
    "for tweet in api.search(q=\"Python\", lang=\"en\", rpp=10):\n",
    "    print(f\"{tweet.user.name}:{tweet.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods for Streaming\n",
    "\n",
    "import json\n",
    "import tweepy\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api):\n",
    "        self.api = api\n",
    "        self.me = api.me()\n",
    "\n",
    "    def on_status(self, tweet):\n",
    "        print(f\"{tweet.user.name}:{tweet.text}\")\n",
    "\n",
    "    def on_error(self, status):\n",
    "        print(\"Error detected\")\n",
    "\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(\"CONSUMER_KEY\", \"CONSUMER_SECRET\")\n",
    "auth.set_access_token(\"ACCESS_TOKEN\", \"ACCESS_TOKEN_SECRET\")\n",
    "\n",
    "# Create API object\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,\n",
    "    wait_on_rate_limit_notify=True)\n",
    "\n",
    "tweets_listener = MyStreamListener(api)\n",
    "stream = tweepy.Stream(api.auth, tweets_listener)\n",
    "stream.filter(track=[\"Python\", \"Django\", \"Tweepy\"], languages=[\"en\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
