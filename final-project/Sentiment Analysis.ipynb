{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from wordcloud import WordCloud\n",
    "#from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>0</td>\n",
       "      <td>wild</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>61</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>125</td>\n",
       "      <td>rt  if you had invested your 1200 stimulus che...</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>3</td>\n",
       "      <td>how is your paper trading account going</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>86</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>132</td>\n",
       "      <td>update gamestop closed today at 194 per share ...</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>1906</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>6</td>\n",
       "      <td>rt   daily letter this morning is pretty spot ...</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name  retweet_count                                               text  \\\n",
       "0  Pomp              0                                              wild    \n",
       "1  Pomp            125  rt  if you had invested your 1200 stimulus che...   \n",
       "2  Pomp              3            how is your paper trading account going   \n",
       "3  Pomp            132  update gamestop closed today at 194 per share ...   \n",
       "4  Pomp              6  rt   daily letter this morning is pretty spot ...   \n",
       "\n",
       "   created_at  favourite_count hashtags  \n",
       "0  2021-03-08               61       []  \n",
       "1  2021-03-08                0       []  \n",
       "2  2021-03-08               86       []  \n",
       "3  2021-03-08             1906       []  \n",
       "4  2021-03-08                0       []  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data = pd.read_csv('clean_twitter_dataset.csv') \n",
    "twitter_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24341 entries, 0 to 24340\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   name             24341 non-null  object\n",
      " 1   retweet_count    24341 non-null  int64 \n",
      " 2   text             24237 non-null  object\n",
      " 3   created_at       24341 non-null  object\n",
      " 4   favourite_count  24341 non-null  int64 \n",
      " 5   hashtags         24341 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "twitter_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tweets contienen información numérica que podría ser de utilidad, sin embargo para el mvp será descartada y nos centraremos unicamente en el sentimiento de los mensajes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erase stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Split in words\n",
    "2. Keep only alphabetic characters\n",
    "3. apply stopworsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitWords(tweet):\n",
    "    \n",
    "    text = str(tweet)\n",
    "    words = text.split()\n",
    "    words_no_punc = []\n",
    "    \n",
    "    for w in words:\n",
    "        if w.isalpha():\n",
    "            words_no_punc.append(w.lower())      \n",
    "        \n",
    "    return words_no_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['sentiment_a'] = twitter_data['text'].apply(lambda x: splitWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopWords(words):\n",
    "    stop_en = stopwords.words('english')\n",
    "    return stop_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['stopwords'] = twitter_data['text'].apply(lambda x: stopWords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data['stopwords'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column clean words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanWords(words, stopwords):\n",
    "    clean_words = []\n",
    "\n",
    "    if words not in stopwords:\n",
    "        clean_words.append(words)\n",
    "            \n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['clean_words'] = twitter_data['text'].apply(lambda x: cleanWords(str(x),twitter_data['stopwords'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                 [ wild ]\n",
       "1        [rt  if you had invested your 1200 stimulus ch...\n",
       "2               [ how is your paper trading account going]\n",
       "3        [update gamestop closed today at 194 per share...\n",
       "4        [rt   daily letter this morning is pretty spot...\n",
       "                               ...                        \n",
       "24336       [rt  update etc trading volume within 24hour ]\n",
       "24337    [ no matter how good of a trader you are 100 w...\n",
       "24338    [etc is hot now preparing for upmove long time...\n",
       "24339    [ if everybody gets dumped on why does everyon...\n",
       "24340                  [ dreams great messengers they are]\n",
       "Name: clean_words, Length: 24341, dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip retweet:\n",
    "\n",
    "def stripRetweet(tweet):\n",
    "    pattern = r\"rt\\s+\"\n",
    "    no_mentions = re.sub(pattern,\"\",tweet)\n",
    "    return no_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['clean_words'] = twitter_data['clean_words'].apply(lambda x: stripRetweet(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favourite_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>sentiment_a</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>clean_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>0</td>\n",
       "      <td>wild</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>61</td>\n",
       "      <td>[]</td>\n",
       "      <td>[wild]</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>[' wild ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>125</td>\n",
       "      <td>rt  if you had invested your 1200 stimulus che...</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[rt, if, you, had, invested, your, stimulus, c...</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>['if you had invested your 1200 stimulus check...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>3</td>\n",
       "      <td>how is your paper trading account going</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>86</td>\n",
       "      <td>[]</td>\n",
       "      <td>[how, is, your, paper, trading, account, going]</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>[' how is your paper trading account going']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>132</td>\n",
       "      <td>update gamestop closed today at 194 per share ...</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>1906</td>\n",
       "      <td>[]</td>\n",
       "      <td>[update, gamestop, closed, today, at, per, sha...</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>['update gamestop closed today at 194 per shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pomp</td>\n",
       "      <td>6</td>\n",
       "      <td>rt   daily letter this morning is pretty spot ...</td>\n",
       "      <td>2021-03-08</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[rt, daily, letter, this, morning, is, pretty,...</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>['daily letter this morning is pretty spot on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24336</th>\n",
       "      <td>CryptoYoda</td>\n",
       "      <td>21</td>\n",
       "      <td>rt  update etc trading volume within 24hour</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[rt, update, etc, trading, volume, within]</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>['update etc trading volume within 24hour ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24337</th>\n",
       "      <td>CryptoYoda</td>\n",
       "      <td>0</td>\n",
       "      <td>no matter how good of a trader you are 100 wi...</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>17</td>\n",
       "      <td>[]</td>\n",
       "      <td>[no, matter, how, good, of, a, trader, you, ar...</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>[' no matter how good of a trader you are 100 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24338</th>\n",
       "      <td>CryptoYoda</td>\n",
       "      <td>76</td>\n",
       "      <td>etc is hot now preparing for upmove long time ...</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>184</td>\n",
       "      <td>[]</td>\n",
       "      <td>[etc, is, hot, now, preparing, for, upmove, lo...</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>['etc is hot now preparing for upmove long tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24339</th>\n",
       "      <td>CryptoYoda</td>\n",
       "      <td>0</td>\n",
       "      <td>if everybody gets dumped on why does everyone...</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>[if, everybody, gets, dumped, on, why, does, e...</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>[' if everybody gets dumped on why does everyo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24340</th>\n",
       "      <td>CryptoYoda</td>\n",
       "      <td>0</td>\n",
       "      <td>dreams great messengers they are</td>\n",
       "      <td>2017-05-29</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[dreams, great, messengers, they, are]</td>\n",
       "      <td>[i, me, my, myself, we, our, ours, ourselves, ...</td>\n",
       "      <td>[' dreams great messengers they are']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24341 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  retweet_count  \\\n",
       "0            Pomp              0   \n",
       "1            Pomp            125   \n",
       "2            Pomp              3   \n",
       "3            Pomp            132   \n",
       "4            Pomp              6   \n",
       "...           ...            ...   \n",
       "24336  CryptoYoda             21   \n",
       "24337  CryptoYoda              0   \n",
       "24338  CryptoYoda             76   \n",
       "24339  CryptoYoda              0   \n",
       "24340  CryptoYoda              0   \n",
       "\n",
       "                                                    text  created_at  \\\n",
       "0                                                  wild   2021-03-08   \n",
       "1      rt  if you had invested your 1200 stimulus che...  2021-03-08   \n",
       "2                how is your paper trading account going  2021-03-08   \n",
       "3      update gamestop closed today at 194 per share ...  2021-03-08   \n",
       "4      rt   daily letter this morning is pretty spot ...  2021-03-08   \n",
       "...                                                  ...         ...   \n",
       "24336       rt  update etc trading volume within 24hour   2017-05-29   \n",
       "24337   no matter how good of a trader you are 100 wi...  2017-05-29   \n",
       "24338  etc is hot now preparing for upmove long time ...  2017-05-29   \n",
       "24339   if everybody gets dumped on why does everyone...  2017-05-29   \n",
       "24340                   dreams great messengers they are  2017-05-29   \n",
       "\n",
       "       favourite_count hashtags  \\\n",
       "0                   61       []   \n",
       "1                    0       []   \n",
       "2                   86       []   \n",
       "3                 1906       []   \n",
       "4                    0       []   \n",
       "...                ...      ...   \n",
       "24336                0       []   \n",
       "24337               17       []   \n",
       "24338              184       []   \n",
       "24339                6       []   \n",
       "24340                1       []   \n",
       "\n",
       "                                             sentiment_a  \\\n",
       "0                                                 [wild]   \n",
       "1      [rt, if, you, had, invested, your, stimulus, c...   \n",
       "2        [how, is, your, paper, trading, account, going]   \n",
       "3      [update, gamestop, closed, today, at, per, sha...   \n",
       "4      [rt, daily, letter, this, morning, is, pretty,...   \n",
       "...                                                  ...   \n",
       "24336         [rt, update, etc, trading, volume, within]   \n",
       "24337  [no, matter, how, good, of, a, trader, you, ar...   \n",
       "24338  [etc, is, hot, now, preparing, for, upmove, lo...   \n",
       "24339  [if, everybody, gets, dumped, on, why, does, e...   \n",
       "24340             [dreams, great, messengers, they, are]   \n",
       "\n",
       "                                               stopwords  \\\n",
       "0      [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "1      [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "2      [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "3      [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "4      [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "...                                                  ...   \n",
       "24336  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "24337  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "24338  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "24339  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "24340  [i, me, my, myself, we, our, ours, ourselves, ...   \n",
       "\n",
       "                                             clean_words  \n",
       "0                                             [' wild ']  \n",
       "1      ['if you had invested your 1200 stimulus check...  \n",
       "2           [' how is your paper trading account going']  \n",
       "3      ['update gamestop closed today at 194 per shar...  \n",
       "4      ['daily letter this morning is pretty spot on ...  \n",
       "...                                                  ...  \n",
       "24336       ['update etc trading volume within 24hour ']  \n",
       "24337  [' no matter how good of a trader you are 100 ...  \n",
       "24338  ['etc is hot now preparing for upmove long tim...  \n",
       "24339  [' if everybody gets dumped on why does everyo...  \n",
       "24340              [' dreams great messengers they are']  \n",
       "\n",
       "[24341 rows x 9 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysis(clean_words):\n",
    "    \n",
    "    variable = TextBlob(clean_words).sentiment\n",
    "    \n",
    "    return variable.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['polarity'] = twitter_data['clean_words'].apply(lambda x: sentimentAnalysis(str(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentClassification(number):\n",
    "\n",
    "    category = \"\"\n",
    "    if 1>= number > 0:\n",
    "        category = 'positive'\n",
    "    elif 0 == number:\n",
    "        category = 'neutral'\n",
    "    elif 0 > number >= -1:\n",
    "        category = 'negative'\n",
    "        \n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data['sentiment'] = twitter_data['polarity'].apply(lambda x: sentimentClassification(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative     3422\n",
       "neutral      9939\n",
       "positive    10980\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data.pivot_table(index=['sentiment'], aggfunc='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comma-separated variable file\n",
    "twitter_data = twitter_data.to_csv('clean_tweets.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
